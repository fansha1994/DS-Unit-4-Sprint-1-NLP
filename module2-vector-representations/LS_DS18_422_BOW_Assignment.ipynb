{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS18_422_BOW_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "U4S1-TEST",
      "language": "python",
      "name": "u4s1-test"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fansha1994/DS-Unit-4-Sprint-1-NLP/blob/main/module2-vector-representations/LS_DS18_422_BOW_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn47Bsu6hhga"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Vector Representations\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 2*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyj-f9FDcVFp"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7bcmqfGXrFG"
      },
      "source": [
        "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
        "\n",
        "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcYlc1URXhlC",
        "outputId": "c7e64fc3-1472-40be-d89b-c7cd59afa98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Dependencies for the week (instead of conda)\n",
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/main/requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-02 01:32:14--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/main/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 137 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "\rrequirements.txt      0%[                    ]       0  --.-KB/s               \rrequirements.txt    100%[===================>]     137  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-02 01:32:15 (8.22 MB/s) - ‘requirements.txt’ saved [137/137]\n",
            "\n",
            "Collecting gensim==3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/112bd4258cee11e0baaaba064060eb156475a42362e59e3ff28e7ca2d29d/gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 4.1MB/s \n",
            "\u001b[?25hCollecting pyLDAvis==2.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 58.3MB/s \n",
            "\u001b[?25hCollecting spacy==2.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 37.3MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/7f/366dcba1ba076a88a50bea732dbc033c0c5bbf7876010e6edc67948579d5/scikit_learn-0.22.2-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 56.3MB/s \n",
            "\u001b[?25hCollecting seaborn==0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 57.0MB/s \n",
            "\u001b[?25hCollecting squarify==0.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/2b/2e77c35326efec19819cd1d729540d4d235e6c2a3f37658288a363a67da5/squarify-0.4.3-py3-none-any.whl\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (4.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (4.6.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.35.1)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.1.3)\n",
            "Collecting thinc<7.4.0,>=7.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 48.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (50.3.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3->-r requirements.txt (line 3)) (1.0.2)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (5.3.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 7)) (4.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 9)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 9)) (2.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (20.2.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (1.9.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (8.5.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 3)) (2.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.3->-r requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 7)) (19.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 7)) (4.6.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->-r requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->-r requirements.txt (line 7)) (0.2.5)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=8bbcd31dd0931c7370942ecda23b720f9be24c01ade02f06497aa377be6cec4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: gensim, funcy, pyLDAvis, thinc, spacy, scikit-learn, seaborn, squarify\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: seaborn 0.11.0\n",
            "    Uninstalling seaborn-0.11.0:\n",
            "      Successfully uninstalled seaborn-0.11.0\n",
            "Successfully installed funcy-1.15 gensim-3.8.1 pyLDAvis-2.1.2 scikit-learn-0.22.2 seaborn-0.9.0 spacy-2.2.3 squarify-0.4.3 thinc-7.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzKV-G_m8RD3",
        "outputId": "0ba33c46-ec97-4135-eb92-5514603b238d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg  # Can do lg, takes awhile\n",
        "# Also on Colab, need to restart runtime after this step!"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.3.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=cdeb7280db1b7cc740accdfb1b1249fedd2f09d59bfe5b372e59e8d7cad40253\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hjjc1f8d/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmej1dqf8RfR",
        "outputId": "17d95e5e-0e4b-4937-e60a-d7e00fc39c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/main/module2-vector-representations/data/job_listings.csv\"\n",
        "\n",
        "job_listings = pd.read_csv(url)\n",
        "print(job_listings.shape)\n",
        "job_listings.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
              "      <td>Data scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
              "      <td>Data Scientist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                         title\n",
              "0           0  ...               Data scientist \n",
              "1           1  ...              Data Scientist I\n",
              "2           2  ...  Data Scientist - Entry Level\n",
              "3           3  ...                Data Scientist\n",
              "4           4  ...                Data Scientist\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PCTB0R5EKap"
      },
      "source": [
        "text = job_listings['description'][0]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQwd14nM_M-a",
        "outputId": "48b73070-ac5f-4183-f613-74345fa8db69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "cleantext = BeautifulSoup(text, 'html.parser').text\n",
        "print(cleantext)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\"Job Requirements:\\nConceptual understanding in Machine Learning models like Nai\\xc2\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\nHands on experience in SQL/Hive or similar programming language\\nMust show past work via GitHub, Kaggle or any other published article\\nMaster's degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\nApply Now\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Y9mmro_NJ3",
        "outputId": "d64f6433-e21a-4829-82be-06dce490a311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "job_listings['clean_description'] = [BeautifulSoup(clean_description, 'html.parser').text for clean_description in job_listings['description']] \n",
        "job_listings.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "      <th>clean_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
              "      <td>Data scientist</td>\n",
              "      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "      <td>b'As a Data Scientist you will be working on c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                  clean_description\n",
              "0           0  ...  b\"Job Requirements:\\nConceptual understanding ...\n",
              "1           1  ...  b'Job Description\\n\\nAs a Data Scientist 1, yo...\n",
              "2           2  ...  b'As a Data Scientist you will be working on c...\n",
              "3           3  ...  b'$4,969 - $6,756 a monthContractUnder the gen...\n",
              "4           4  ...  b'Location: USA \\xe2\\x80\\x93 multiple location...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tK32gmS_NT1",
        "outputId": "fe2604f0-75ae-4a34-b624-59b5c156398f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "job_listings['clean_description'][0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'b\"Job Requirements:\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\\\nHands on experience in SQL/Hive or similar programming language\\\\nMust show past work via GitHub, Kaggle or any other published article\\\\nMaster\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\\\nApply Now\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsI9YIKt_NR8",
        "outputId": "797970f6-12a7-47fe-e598-2974554150dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "job_listings['description'][0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'b\"<div><div>Job Requirements:</div><ul><li><p>\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\\\n</li><li><p>Master\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\\\nApply Now</div></div></div></div></div></div></div><div></div>\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QovEVDRBHL9Y"
      },
      "source": [
        "text2 = job_listings['clean_description'][0]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MohcYNKHA-j",
        "outputId": "7b6faf07-d906-4bd0-829d-7ed4a7d7dfd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "text2 = re.sub(\"[^a-zA-Z.,!?']+\",\" \", text2)\n",
        "text2"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"b Job Requirements nConceptual understanding in Machine Learning models like Nai xc xa ve Bayes, K Means, SVM, Apriori, Linear Logistic Regression, Neural, Random Forests, Decision Trees, K NN along with hands on experience in at least of them nIntermediate to expert level coding skills in Python R. Ability to write functions, clean and efficient data manipulation are mandatory for this role nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot , dplyr, tidyR in R nAbility to communicate Model findings to both Technical and Non Technical stake holders nHands on experience in SQL Hive or similar programming language nMust show past work via GitHub, Kaggle or any other published article nMaster's degree in Statistics Mathematics Computer Science or any other quant specific field. nApply Now \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOB7KP0VHZcF",
        "outputId": "f2e48eb3-26e6-4544-c2eb-81fa58c59b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "job_listings['clean_description'] = job_listings['clean_description'].apply(lambda x: re.sub(\"[^a-zA-Z.,!?']+\",\" \", x))\n",
        "job_listings.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "      <th>clean_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
              "      <td>Data scientist</td>\n",
              "      <td>b Job Requirements nConceptual understanding i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>b'Job Description n nAs a Data Scientist , you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "      <td>b'As a Data Scientist you will be working on c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>b' , , a monthContractUnder the general superv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>b'Location USA xe x x multiple locations n yea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                  clean_description\n",
              "0           0  ...  b Job Requirements nConceptual understanding i...\n",
              "1           1  ...  b'Job Description n nAs a Data Scientist , you...\n",
              "2           2  ...  b'As a Data Scientist you will be working on c...\n",
              "3           3  ...  b' , , a monthContractUnder the general superv...\n",
              "4           4  ...  b'Location USA xe x x multiple locations n yea...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSRNbC25KgqG",
        "outputId": "cfd6976d-0450-41fa-85bc-8c8896567c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "job_listings.columns"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'description', 'title', 'clean_description', 'tokens'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdVjKk5VKWc6"
      },
      "source": [
        "job_listings = job_listings.drop('Unnamed: 0', axis=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C4xFZNtX1m2"
      },
      "source": [
        "## 2) Use Spacy to tokenize the listings "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhUHuMr-X-II",
        "outputId": "ac714e87-c269-4e14-8630-689ad48420d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "job_listings.isnull().sum()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "description          0\n",
              "title                0\n",
              "clean_description    0\n",
              "tokens               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7SWOm6SH8_-"
      },
      "source": [
        "# we will tokenize using spacy\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w1HIqKnH9H7",
        "outputId": "02c85fa0-cde0-46d4-ccb5-f6c6d1d0debf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        " for doc in nlp.pipe(job_listings['clean_description'][:10]):\n",
        "  print(doc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b Job Requirements nConceptual understanding in Machine Learning models like Nai xc xa ve Bayes, K Means, SVM, Apriori, Linear Logistic Regression, Neural, Random Forests, Decision Trees, K NN along with hands on experience in at least of them nIntermediate to expert level coding skills in Python R. Ability to write functions, clean and efficient data manipulation are mandatory for this role nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot , dplyr, tidyR in R nAbility to communicate Model findings to both Technical and Non Technical stake holders nHands on experience in SQL Hive or similar programming language nMust show past work via GitHub, Kaggle or any other published article nMaster's degree in Statistics Mathematics Computer Science or any other quant specific field. nApply Now \n",
            "b'Job Description n nAs a Data Scientist , you will help us build machine learning models, data pipelines, and micro services to help our clients navigate their healthcare journey. You will do so by empowering and improving the next generation of Accolade Applications and user experiences. nA day in the life xe x xa nWork with a small agile team to design and develop mobile applications in an iterative fashion. nWork with a tight knit group of development team members in Seattle. nContribute to best practices and help guide the future of our applications. nOperates effectively as a collaborative member of the development team. nOperates effectively as an individual for quick turnaround of enhancements and fixes. nResponsible for meeting expectations and deliverables on time with high quality. nDrive and implement new features within our mobile applications. nPerform thorough manual testing and writing test cases that cover all areas. nIdentify new development tools approaches that will increase code quality, efficiency, and best practices. nDevelop and champion the the development processes, coding style guidelines, and architectural designs necessary to innovate and maintain great product quality. nEffectively turns design documents and graphics into performant, usable UI. nDemonstrates creative, technical, and analytical skills. nDemonstrates ability to communicate effectively in both technical and business environments n nQualifications n nWhat we are looking for xe x xa nMaster xe x x s Degree in Computer Science, Math, or related field. nComputer Science fundamentals, as illustrated through algorithm design, problem solving, and complexity analysis. nMust have year real world experience developing and deploying micro services or data pipelines nMust have a fundamental understanding of key machine learning concepts, such as accuracy measures, cross validation, and open source machine learning libraries nFluent in Python and SQL nProficient with writing unit functional tests and familiar with automation frameworks nExperience with cloud infrastructure, such as AWS or Azure, is a plus. nExperience with distributed data pipelines, such as a Spark, is a plus. nStrong written and oral communication skills. nDesire and willingness to work in an Agile, collaborative, innovative, flexible, and team oriented environment nHands on, detail oriented, methodical inquisitive nA motivated self starter with a solid level of experience that quickly grasps complex challenges nA skillful communicator with experience working with technical management teams n A service oriented person who thinks Customer First nFast fail entrepreneurial spirit nThrives in a fast paced environment where continuous improvement is the norm and the bar for quality is extremely high nExcited by the challenges of working in a product team undergoing rapid, international growth nAdditional Information n nWhat is important to us nCreating an enduring company that is hyper focused on our culture and making a meaningful impact in the lives of our employees, members and customers. The secret to our success is nWe find joy and purpose in serving others nMaking a difference in our members xe x x and customers xe x x lives is what we do. Even when it xe x x s hard, we do the right thing for the right reasons. nWe are strong individually and together, we xe x x re powerful nTrusting in our colleagues and embracing their different backgrounds and experiences enable us to solve tough problems in creative ways, having fun along the way. nWe roll up our sleeves and get stuff done nResults motivate us. And we aren 't afraid of the hard work or tough decisions needed to get us there. nWe xe x x re boldly and relentlessly reinventing healthcare nWe 're curious and act big not afraid to knock down barriers or take calculated risks to change the world, one person at a time. nAll your information will be kept confidential according to EEO guidelines.'\n",
            "b'As a Data Scientist you will be working on consulting side of our business. You will be responsible for analyzing large, complex datasets and identify meaningful patterns that lead to actionable recommendations. You will be performing thorough testing and validation of models, and support various aspects of the business with data analytics. nAbility to do statistical modeling, build predictive models and leverage machine learning algorithms. nThis position will combine the typical Data Scientist math and analytical skills, with research, advanced business, communication, and presentation skills. nPrimary job location is in Sacramento, but work from home option is available. n nQualifications nBachelors, MS or PhD in a relevant field Computer Science, Engineering, Statistics, Physics, Applied Math nExperience in R and or Python is preferred'\n",
            "b' , , a monthContractUnder the general supervision of Professors Dana Mukamel and Kai Zheng, the incumbent will join the CalMHSA Mental Health Tech Suite Innovation INN Evaluation Team. This large, statewide multi year study will evaluate the effectiveness of two new and innovative applications offered to people with mental health conditions, which include opportunities for online chatting between users and online listeners Responsibilities of the incumbent will include managing and analyzing text data created by users of the two mental health applications as part of the research and evaluation objectives of the team. The incumbent will collaborate with faculty and other team researchers, and will be expected to create under supervision and direction variables describing the usage of the apps, the interactions between users, and the effectiveness of the apps. The incumbent will also be expected to interact with the vendors of the apps around data issues. n nThe University of California, Irvine is an Equal Opportunity Affirmative Action Employer advancing inclusive excellence. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, protected veteran status, or other protected categories covered by the UC nondiscrimination policy. n nSalary Monthly , . , . nTotal Hours , M F nContract Position. nFinal candidate subject to background check. nAs a federal contractor, UC Irvine is required to use E Verify to confirm the work status of individuals assigned to perform substantial work under certain federal contracts subcontracts. n nPlease attach your resume.'\n",
            "b'Location USA xe x x multiple locations n years of Analytics experience nUnderstand business requirements and technical requirements nCan handle data extraction, preparation and transformation nCreate and implement data models'\n",
            "b'Create various Business Intelligence Analytical reports, visualization and dashboards with BI tools like Tableau, Power BI or similar nUtilize experience in scientific data, logic programming and calculated columns, and decision making nDevelop and maintain dashboards for KPIs, purchase trends with time series and customer flows with Tableau and Teradata nDevelop recommendation models utilizing machine learning and predictive analysis with supervised and unsupervised algorithms like random forest, support vector machine and k means clustering nUtilize experience with SQL with strong concepts of database, data warehouse and metadata nWork closely with frontend web developer and UX designer on improving online shopping experience and deploying business strategies like promotion or similar nAnalyze customer behaviors and purchase trends to create customized recommended items nConduct and apply A B test to monitor and test new or modified features for online shopping experiences across desktop and mobile platforms nCollect real time data from A B test and generate feedback reports for presentations and communications to other teams, both technical and non technical nUtilize clustering models to categorize customers and generate optimized business strategies for different categories nCreate novel computational approaches and analytical tools as required by market and business goals nDesign databases and develop algorithms for processing and analyzing purchase, device information and customer information nAnalyze geographic trends for online shopper sessions with business strategy implications and present on dashboard nConsult with clients to analyze business problem, setup market goals, recommend technology based solutions, or determine computational strategies nWork with large data access, admin configuration and application data services nWork with business stakeholders to identify requirements and outcomes, and to frame meaningful business scenarios that impact critical business functions nDesign experiments, test hypothesis, build models to conduct data analysis and design algorithms and utilize appropriate designs to conduct analytics and discover patterns nKey Skills Python, R, SQL, Tableau, Excel'\n",
            "b'As Spotify Premium swells to over M subscribers around the globe, we are looking for new ways to continue to grow our subscription business. You would be joining Spotify on the Premium Analytics team, a core business strategy and insights team, as an Associate Data Scientist. In this unique position, your work would be essential in shaping how Spotify is able to grow through data driven recommendations, new product offerings and innovative marketing efforts. You will see first hand how your work translates into new strategies, products, and consumer experiences as we enter a new phase in Spotify Premium xe x x s life. n nYou will work with a global team of world class analysts, data scientists, business managers, marketers, and engineers. We are all passionate about what we do and move forward with high impact projects at a high pace. Learning and improving is part of our daily routine, and you will be free to develop your own skills and ways of working. At your fingertips you xe x x ll have access to petabytes of data, and will get the opportunity to be creative with how you drive insights and strategies from that. Above all, your work will impact the way the world experiences music. n nWhat You xe x x ll Do n nDevelop data driven strategies to drive the growth of Spotify subscribers nCreate and communicate actionable recommendations that improve our product conversion and migration metrics. nWork with everything from advanced algorithmic data analysis and AB test setup to business analysis and modeling nWork closely with business stakeholders to understand the change they are driving and help them discover new opportunities for growth. nWho Are You n nYou are an open minded, creative person with an interest in analyses and data science nYou have some professional experience working with data analysis year nYou are comfortable with the whole analytical process from identifying insight gaps to designing and running initiatives to fill them nYou have worked hands on synthesizing insights from data using tools such as Python, R, SQL, SAS, SPSS, Minitab and or Hadoop nYou are a communicative person that values building strong relationships with colleagues and partners, you are experienced in presenting insights and recommendations to partners or clients'\n",
            "b Everytown for Gun Safety, the nation's largest gun violence prevention advocacy group, is seeking a Data Scientist. The Research Department studies how gun violence occurs in America and identifies the best policies and interventions to prevent and address it. In this role, the Data Scientist will need to understand and communicate about the various types of gun violence, who it impacts, and how it impacts different communities and populations differently. You must be committed to addressing gun violence in diverse communities around the country. n nThe Data Scientist will be the policy data lead for the organization, responsible for advanced data management, analysis, and visualization. The Data Scientist reports to the Principal Researcher. n nWe'll trust you to take on the following responsibilities n nServe as the lead data analyst on the team, responsible for the accuracy and appropriate use of all calculations and findings nConduct original analysis and identify new avenues for statistical analysis on gun violence prevention, policies, and interventions to support Everytown for Gun Safety advocacy and research products and campaigns nAnalyze large datasets using various software packages R, STATA, SPSS, SQL, Python, and or others nOversee staff to obtain, organize, and update datasets of frequent reference e.g., CDC fatal and nonfatal injury data FBI Supplementary Homicide Report data FBI background check data and other federal , state , and city level data related to gun violence prevention nOptimize and ensure integrity of all databases managed across the organization nLead efforts to identify new datasets and opportunities for original analysis, as well as their application across Departments nDirect and implement data visualization efforts and review all products from a data perspective nServe as the subject matter expert on economic analysis of gun violence nServe as a mentor to the team and identify training and development opportunities nContribute to the publication of analytical reports, compelling advocacy materials, and other research based products to support Everytown's legislative and outreach advocacy goals nClearly translate the implications of research findings from Everytown original research and the work of scholars in the field so that practitioners and policymakers can implement new laws effectively and enforce existing policies n nThe ideal candidate will have n nAdvanced degree in a quantitative field or equivalent professional experience n years applied experience in research, policy, and or economics economics experience preferred nFluency with multiple research methods, both quantitative and qualitative, such as multivariate statistics, cluster analysis, survey research, regression analysis, classification modelling, hypothesis testing, and or composite index creation nExperience working with large datasets using at least one software package R, STATA, SPSS, SQL, Python, and or others nSignificant data management and data visualization experience nFamiliarity with government generated data and information sources city, state, and federal , e.g. U.S. Census data, preferred nDemonstrated ability to effectively communicate research findings to a broad range of audiences nThe ability to work in a dynamic and fast paced environment with an open floor plan n nReasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. n nEverytown for Gun Safety provides equal employment opportunities EEO to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state and local laws. n nCandidates who identify as members of historically underrepresented groups are highly encouraged to apply. A diverse workforce and open culture are at the heart of our organization and vital to our success. \n",
            "b MS in a quantitative discipline such as Statistics, Mathematics, Physics, Engineering, Computer Science or Economics years work experienceProficiency in at least one statistical software package such as Python, R or MatlabExpertise using SQL for acquiring and transforming dataOutstanding quantitative modeling and statistical analysis skillsExcellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams and business audiences n nWhere will Amazon's growth come from in the next year? What about over the next five? Which product lines are poised to quintuple in size? Are we investing enough in our infrastructure, or too much? How do our customers react to changes in prices, product selection, or delivery times? nThese are among the most important questions at Amazon today. The Topline Forecast team in the Supply Chain Optimization Technologies SCOT organization is dedicated to answering these questions using statistical methods. We develop cutting edge data pipelines, build accurate predictive models, and deploy automated software solutions to provide forecasting insights to business leaders at the most senior levels throughout the company. We are looking for a talented, driven, and analytical researcher to help us answer these and many more questions. nThis Data Scientist role will design quantitative systems and forecasting models that generate multi billion dollar predictions of the highest level of visibility and importance for Amazon's financial and operational planning. A successful candidate will be a problem solver who enjoys diving into data, is excited by difficult modeling challenges, and possesses strong communication skills to effectively interface between technical and business teams. nAs a Data Scientist on the Topline team, you will collaborate directly with economists and statisticians to produce modeling solutions, you will partner with software developers and data engineers to build end to end data pipelines and production code, and you will have exposure to senior leadership as we communicate results and provide scientific guidance to the business. nKey Responsibilities nImplement statistical and machine learning methods to solve specific business problemsImprove upon existing methodologies by developing new data sources, testing model enhancements, and fine tuning model parametersDirectly contribute to the design and development of automated forecasting systemsBuild customer facing reporting tools to provide insights and metrics which track forecast performance and explain varianceCollaborate with researchers, software developers, and business leaders to define product requirements, provide analytical support, and communicate feedback nAmazon is an Equal Opportunity Employer xe x x Minority Female Disability Veteran Gender Identity Sexual Orientation. n nExperience building complex data visualizationsExperience working in command line Linux environmentsExperience with object oriented programming languagesExperience with causal inference, applied time series modeling or machine learning forecasting applicationsStrong project management skills \n",
            "b'Slack is hiring experienced data scientists to join our Lifecycle team. The Lifecycle team xe x x s mission is to build product experiences that help companies of all sizes adopt and scale Slack within their organization. These product experiences include team and user onboarding, payments and billing systems, and the marketing and packaging of paid plans. n nYou will use data to help the team discover opportunities and define appropriate solutions to user problems by performing research into user behavior, defining and applying experimentation standards, and understanding the drivers of business performance. n nSlack has a positive, diverse, and supportive culture xe x x we look for people who are curious, inventive, and work to be a little better every single day. In our work together we aim to be smart, humble, hardworking and, above all, collaborative. If this sounds like a good fit for you, why not say hello? n nWhat you will be doing n nUse data to influence the direction of team roadmaps and inform business decisions nDeepen our understanding of our product, our users, and our business through data and the use of the scientific method nWork with partner teams to define goals and identify metrics that describe our product through data nBe an ambassador for data by improving the availability, understanding, and sophistication with data at Slack nWhat you should have n n years of professional industry experience doing quantitative analysis nA consistent record of using analysis to impact key business or product decisions nThe ability to clearly and effectively communicate the results of complex analyses nUnderstanding of standard data science methodologies nDeep understanding of statistics nAbility to write clean code, especially in R or Python n n nSlack is an Equal Opportunity Employer and participant in the U.S. Federal E Verify program. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply. Slack will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance. n nSlack is a layer of the business technology stack that brings together people, data, and applications xe x x a single place where people can effectively work together, find important information, and access hundreds of thousands of critical applications and services to do their best work. From global Fortune companies to corner markets, businesses and teams of all kinds use Slack to bring the right people together with all the right information. Slack is headquartered in San Francisco, CA and has ten offices around the world. For more information on how Slack makes teams better connected, visit slack.com. nEnsuring a diverse and inclusive workplace where we learn from each other is core to Slack xe x x s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and a pleasant and supportive place to work. nCome do the best work of your life here at Slack.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpPL3XHUH9PD"
      },
      "source": [
        "tokens = []\n",
        "\n",
        "for doc in nlp.pipe(job_listings['clean_description']):\n",
        "\n",
        "  doc_tokens = []\n",
        "\n",
        "  for token in doc:\n",
        "\n",
        "    if (token.is_stop == False) & (token.is_punct ==False) & (token.pos_ != 'PRON'):\n",
        "      doc_tokens.append(token.text.lower())\n",
        "\n",
        "  tokens.append(doc_tokens)\n",
        "\n",
        "# adding a new column\n",
        "job_listings['tokens'] = tokens"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zwgGyLXJL4g",
        "outputId": "eeb23dc7-ac34-480d-d056-9b659724d706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "job_listings.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>description</th>\n",
              "      <th>title</th>\n",
              "      <th>clean_description</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
              "      <td>Data scientist</td>\n",
              "      <td>b Job Requirements nConceptual understanding i...</td>\n",
              "      <td>[b, job, requirements, nconceptual, understand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>b'Job Description n nAs a Data Scientist , you...</td>\n",
              "      <td>[b'job, description, n, nas, data, scientist, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
              "      <td>Data Scientist - Entry Level</td>\n",
              "      <td>b'As a Data Scientist you will be working on c...</td>\n",
              "      <td>[b'as, data, scientist, working, consulting, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>b' , , a monthContractUnder the general superv...</td>\n",
              "      <td>[b, monthcontractunder, general, supervision, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>b'Location USA xe x x multiple locations n yea...</td>\n",
              "      <td>[b'location, usa, xe, x, x, multiple, location...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                             tokens\n",
              "0           0  ...  [b, job, requirements, nconceptual, understand...\n",
              "1           1  ...  [b'job, description, n, nas, data, scientist, ...\n",
              "2           2  ...  [b'as, data, scientist, working, consulting, b...\n",
              "3           3  ...  [b, monthcontractunder, general, supervision, ...\n",
              "4           4  ...  [b'location, usa, xe, x, x, multiple, location...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lgCZNL_YycP"
      },
      "source": [
        "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2PZ8Pj_YxcF"
      },
      "source": [
        "# Apply CountVectorizer to our Data\n",
        "# Use custom Spacy Vectorizer\n",
        "# BBC articles in `data` variable\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(stop_words='english', max_features=2000)\n",
        "\n",
        "#Learn our Vocab\n",
        "vect.fit(job_listings['clean_description'])\n",
        "\n",
        "# Get sparse dtm\n",
        "dtm = vect.transform(job_listings['clean_description'])\n",
        "\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-EtX-NjJeGW",
        "outputId": "ee049205-5672-42de-8488-520748c5a083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "dtm.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>ab</th>\n",
              "      <th>abilities</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>academic</th>\n",
              "      <th>accelerate</th>\n",
              "      <th>accept</th>\n",
              "      <th>access</th>\n",
              "      <th>accessible</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>accommodations</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>accordance</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accountability</th>\n",
              "      <th>accounts</th>\n",
              "      <th>accredited</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accurate</th>\n",
              "      <th>achieve</th>\n",
              "      <th>achieving</th>\n",
              "      <th>acquire</th>\n",
              "      <th>acquisition</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>actionable</th>\n",
              "      <th>actions</th>\n",
              "      <th>active</th>\n",
              "      <th>actively</th>\n",
              "      <th>activities</th>\n",
              "      <th>activity</th>\n",
              "      <th>actuarial</th>\n",
              "      <th>acumen</th>\n",
              "      <th>ad</th>\n",
              "      <th>add</th>\n",
              "      <th>addition</th>\n",
              "      <th>additional</th>\n",
              "      <th>address</th>\n",
              "      <th>...</th>\n",
              "      <th>ways</th>\n",
              "      <th>web</th>\n",
              "      <th>website</th>\n",
              "      <th>week</th>\n",
              "      <th>weeks</th>\n",
              "      <th>welcome</th>\n",
              "      <th>wellness</th>\n",
              "      <th>wide</th>\n",
              "      <th>wider</th>\n",
              "      <th>willing</th>\n",
              "      <th>willingness</th>\n",
              "      <th>win</th>\n",
              "      <th>women</th>\n",
              "      <th>word</th>\n",
              "      <th>work</th>\n",
              "      <th>worked</th>\n",
              "      <th>workers</th>\n",
              "      <th>workflows</th>\n",
              "      <th>workforce</th>\n",
              "      <th>working</th>\n",
              "      <th>workplace</th>\n",
              "      <th>works</th>\n",
              "      <th>world</th>\n",
              "      <th>worldwide</th>\n",
              "      <th>wrangling</th>\n",
              "      <th>write</th>\n",
              "      <th>writing</th>\n",
              "      <th>written</th>\n",
              "      <th>www</th>\n",
              "      <th>xa</th>\n",
              "      <th>xae</th>\n",
              "      <th>xb</th>\n",
              "      <th>xbb</th>\n",
              "      <th>xc</th>\n",
              "      <th>xe</th>\n",
              "      <th>xef</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>york</th>\n",
              "      <th>zf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aa  ab  abilities  ability  able  academic  ...  xe  xef  year  years  york  zf\n",
              "0   0   0          0        1     0         0  ...   0    0     0      0     0   0\n",
              "1   0   0          0        1     0         0  ...   8    0     1      0     0   0\n",
              "2   0   0          0        0     0         0  ...   0    0     0      0     0   0\n",
              "3   0   0          0        0     0         0  ...   0    0     1      0     0   0\n",
              "4   0   0          0        0     0         0  ...   1    0     0      1     0   0\n",
              "\n",
              "[5 rows x 2000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo1iH_UeY7_n"
      },
      "source": [
        "## 4) Visualize the most common word counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9kwxyjcJePz"
      },
      "source": [
        "doc_len = [len(doc) for doc in job_listings['clean_description']]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1z5ky1OJmcL",
        "outputId": "7c789a48-5373-40ee-fc07-a3282780c4b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.distplot(doc_len);"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwFsTqrVZMYi"
      },
      "source": [
        "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gx2gZCbl5Np",
        "outputId": "dfc7da9e-1a24-4a7f-9ee5-155e557646d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instantiate vectorizer object\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "\n",
        "# Create a vocabulary and get word counts per document\n",
        "# Similiar to fit_predict\n",
        "dtm = tfidf.fit_transform(job_listings['clean_description'])\n",
        "\n",
        "# Print word counts\n",
        "\n",
        "# Get feature names to use as dataframe column headers\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "dtm.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>ab</th>\n",
              "      <th>abernathy</th>\n",
              "      <th>abilities</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>absence</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>abstract</th>\n",
              "      <th>abundant</th>\n",
              "      <th>academic</th>\n",
              "      <th>academics</th>\n",
              "      <th>accelerate</th>\n",
              "      <th>accelerating</th>\n",
              "      <th>accept</th>\n",
              "      <th>accepted</th>\n",
              "      <th>accepting</th>\n",
              "      <th>access</th>\n",
              "      <th>accessibility</th>\n",
              "      <th>accessible</th>\n",
              "      <th>accommodate</th>\n",
              "      <th>accommodation</th>\n",
              "      <th>accommodations</th>\n",
              "      <th>accomplish</th>\n",
              "      <th>accomplished</th>\n",
              "      <th>accomplishment</th>\n",
              "      <th>accordance</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accountability</th>\n",
              "      <th>accountable</th>\n",
              "      <th>accounting</th>\n",
              "      <th>accounts</th>\n",
              "      <th>accredited</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accurate</th>\n",
              "      <th>accurately</th>\n",
              "      <th>achieve</th>\n",
              "      <th>achieving</th>\n",
              "      <th>acquire</th>\n",
              "      <th>...</th>\n",
              "      <th>world</th>\n",
              "      <th>worldline</th>\n",
              "      <th>worldwide</th>\n",
              "      <th>worth</th>\n",
              "      <th>wrangle</th>\n",
              "      <th>wrangler</th>\n",
              "      <th>wrangling</th>\n",
              "      <th>write</th>\n",
              "      <th>writing</th>\n",
              "      <th>written</th>\n",
              "      <th>wwe</th>\n",
              "      <th>www</th>\n",
              "      <th>xa</th>\n",
              "      <th>xac</th>\n",
              "      <th>xae</th>\n",
              "      <th>xb</th>\n",
              "      <th>xbb</th>\n",
              "      <th>xbox</th>\n",
              "      <th>xc</th>\n",
              "      <th>xe</th>\n",
              "      <th>xef</th>\n",
              "      <th>xgboost</th>\n",
              "      <th>xpo</th>\n",
              "      <th>year</th>\n",
              "      <th>yeara</th>\n",
              "      <th>yearcollects</th>\n",
              "      <th>yeardescription</th>\n",
              "      <th>years</th>\n",
              "      <th>yearsummary</th>\n",
              "      <th>yearthe</th>\n",
              "      <th>yes</th>\n",
              "      <th>yeti</th>\n",
              "      <th>york</th>\n",
              "      <th>young</th>\n",
              "      <th>yrs</th>\n",
              "      <th>zenreach</th>\n",
              "      <th>zero</th>\n",
              "      <th>zeus</th>\n",
              "      <th>zf</th>\n",
              "      <th>zillow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.061108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.131572</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025199</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.062549</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045088</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.085507</td>\n",
              "      <td>0.030379</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.092847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142399</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041474</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.058882</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.089897</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.097518</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    aa   ab  abernathy  abilities   ability  ...  zenreach  zero  zeus   zf  zillow\n",
              "0  0.0  0.0        0.0        0.0  0.061108  ...       0.0   0.0   0.0  0.0     0.0\n",
              "1  0.0  0.0        0.0        0.0  0.025199  ...       0.0   0.0   0.0  0.0     0.0\n",
              "2  0.0  0.0        0.0        0.0  0.000000  ...       0.0   0.0   0.0  0.0     0.0\n",
              "3  0.0  0.0        0.0        0.0  0.000000  ...       0.0   0.0   0.0  0.0     0.0\n",
              "4  0.0  0.0        0.0        0.0  0.000000  ...       0.0   0.0   0.0  0.0     0.0\n",
              "\n",
              "[5 rows x 5000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dclcer0lM-uk"
      },
      "source": [
        "def tokenize(document):\n",
        "    \n",
        "    doc = nlp(document)\n",
        "    \n",
        "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TWJyZvoLw6t",
        "outputId": "aa29dc13-d7c2-4d57-ab5c-54f4584b9965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "# Tunning Parameters\n",
        "\n",
        "# Instantiate vectorizer object\n",
        "tfidf = TfidfVectorizer(stop_words='english', \n",
        "                        ngram_range=(1,2),\n",
        "                        max_df=.97,\n",
        "                        min_df=3,\n",
        "                        tokenizer=tokenize)\n",
        "\n",
        "# Create a vocabulary and get word counts per document\n",
        "dtm = tfidf.fit_transform(job_listings['clean_description']) # Similiar to fit_predict\n",
        "\n",
        "# Print word counts\n",
        "\n",
        "# Get feature names to use as dataframe column headers\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "dtm.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>.js</th>\n",
              "      <th>aa</th>\n",
              "      <th>aa employer</th>\n",
              "      <th>ab</th>\n",
              "      <th>ab test</th>\n",
              "      <th>abilitie</th>\n",
              "      <th>abilitie nproblem</th>\n",
              "      <th>ability</th>\n",
              "      <th>ability analyze</th>\n",
              "      <th>ability apply</th>\n",
              "      <th>ability build</th>\n",
              "      <th>ability clearly</th>\n",
              "      <th>ability collaborate</th>\n",
              "      <th>ability communicate</th>\n",
              "      <th>ability conduct</th>\n",
              "      <th>ability create</th>\n",
              "      <th>ability deliver</th>\n",
              "      <th>ability develop</th>\n",
              "      <th>ability devise</th>\n",
              "      <th>ability drive</th>\n",
              "      <th>ability effectively</th>\n",
              "      <th>ability experience</th>\n",
              "      <th>ability explain</th>\n",
              "      <th>ability insight</th>\n",
              "      <th>ability juggle</th>\n",
              "      <th>ability lead</th>\n",
              "      <th>ability manage</th>\n",
              "      <th>ability perspective</th>\n",
              "      <th>ability present</th>\n",
              "      <th>ability require</th>\n",
              "      <th>ability research</th>\n",
              "      <th>ability resolve</th>\n",
              "      <th>ability solve</th>\n",
              "      <th>ability support</th>\n",
              "      <th>ability synthesize</th>\n",
              "      <th>ability thing</th>\n",
              "      <th>ability think</th>\n",
              "      <th>ability transform</th>\n",
              "      <th>ability translate</th>\n",
              "      <th>ability use</th>\n",
              "      <th>...</th>\n",
              "      <th>xbb experience</th>\n",
              "      <th>xbb familiarity</th>\n",
              "      <th>xbb strong</th>\n",
              "      <th>xbb utilize</th>\n",
              "      <th>xc</th>\n",
              "      <th>xc xa</th>\n",
              "      <th>xc xae</th>\n",
              "      <th>xc xbb</th>\n",
              "      <th>xe</th>\n",
              "      <th>xe x</th>\n",
              "      <th>xef</th>\n",
              "      <th>xef x</th>\n",
              "      <th>xgboost</th>\n",
              "      <th>y</th>\n",
              "      <th>y combinator</th>\n",
              "      <th>year</th>\n",
              "      <th>year analytical</th>\n",
              "      <th>year apply</th>\n",
              "      <th>year come</th>\n",
              "      <th>year data</th>\n",
              "      <th>year datum</th>\n",
              "      <th>year experience</th>\n",
              "      <th>year hand</th>\n",
              "      <th>year industry</th>\n",
              "      <th>year n</th>\n",
              "      <th>year nrequirements</th>\n",
              "      <th>year professional</th>\n",
              "      <th>year real</th>\n",
              "      <th>year related</th>\n",
              "      <th>year relevant</th>\n",
              "      <th>year simple</th>\n",
              "      <th>year technical</th>\n",
              "      <th>year work</th>\n",
              "      <th>year xe</th>\n",
              "      <th>yearthe</th>\n",
              "      <th>yes</th>\n",
              "      <th>york</th>\n",
              "      <th>york city</th>\n",
              "      <th>york office</th>\n",
              "      <th>yrs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.097901</td>\n",
              "      <td>0.134477</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019369</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.046787</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.113668</td>\n",
              "      <td>0.113668</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014243</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.061927</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.066448</td>\n",
              "      <td>0.066448</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.066610</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 12552 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   .js   aa  aa employer   ab  ab test  ...  yes  york  york city  york office  yrs\n",
              "0  0.0  0.0          0.0  0.0      0.0  ...  0.0   0.0        0.0          0.0  0.0\n",
              "1  0.0  0.0          0.0  0.0      0.0  ...  0.0   0.0        0.0          0.0  0.0\n",
              "2  0.0  0.0          0.0  0.0      0.0  ...  0.0   0.0        0.0          0.0  0.0\n",
              "3  0.0  0.0          0.0  0.0      0.0  ...  0.0   0.0        0.0          0.0  0.0\n",
              "4  0.0  0.0          0.0  0.0      0.0  ...  0.0   0.0        0.0          0.0  0.0\n",
              "\n",
              "[5 rows x 12552 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIk9GoROLxDR",
        "outputId": "324feb4c-45e0-470a-96e7-b245c9421209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dtm.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(426, 12552)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDbG6e4zhhhA"
      },
      "source": [
        "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "bDEs2PjKhhhB",
        "outputId": "c0e95943-a43d-4876-c80d-f26b414efafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Fit on DTM\n",
        "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "nn.fit(dtm)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftn09PdTNoMk",
        "outputId": "0309706a-6b90-46db-c3c9-082ebfff8af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nn.kneighbors([dtm.iloc[0].values])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 1.31484188, 1.32830204, 1.33131178, 1.33362967]]),\n",
              " array([[  0, 115, 274, 336, 403]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8SnXfBRNoUO",
        "outputId": "aed31865-28a7-4ef4-cd94-86929349cdca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Query Using kneighbors \n",
        "nn.kneighbors([dtm.iloc[256]])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 1.20081944, 1.24137639, 1.24137639, 1.26172471]]),\n",
              " array([[256, 199, 122,  55, 201]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDepp4w9NodE",
        "outputId": "0cc0c5f0-b1eb-4797-cade-1d6b9004cd48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "job_listings['clean_description'][256][:199]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"b'Role Summary nThe CCS Data Scientist is responsible for supporting the CCS digital service operations teams with data analytics that drive improved remote service efficiency and improved customer e\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiDfTWceoRkH"
      },
      "source": [
        "## Stretch Goals\n",
        "\n",
        " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
        " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
        " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
        " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
        "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
        " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
      ]
    }
  ]
}